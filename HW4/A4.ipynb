{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyCOyQFK7YId"
      },
      "source": [
        "# MIS 583 Assignment 4: Self-supervised and transfer learning on CIFAR10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa4OJqMT7YIi"
      },
      "source": [
        "Before we start, please put your name and SID in following format: <br>\n",
        ": LASTNAME Firstname, ?00000000   //   e.g.) 李晨愷 M114020035"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csYjKs3y7YIj"
      },
      "source": [
        "**Your Answer:**    \n",
        "Hi I'm 賴壹誠, M124020042."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWMWW8Ab_345"
      },
      "source": [
        "## Google Colab Setup\n",
        "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
        "\n",
        "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!) and copy the authorization code into the text box that appears below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vH4wc4iD_6w_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f15ca6-ce2b-4e39-9d8c-04d018f53098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um5DJvBwb6xT"
      },
      "source": [
        "# Data Setup (5 points)\n",
        "\n",
        "The first thing to do is implement a dataset class to load rotated CIFAR10 images with matching labels. Since there is already a CIFAR10 dataset class implemented in `torchvision`, we will extend this class and modify the `__get_item__` method appropriately to load rotated images.\n",
        "\n",
        "Each rotation label should be an integer in the set {0, 1, 2, 3} which correspond to rotations of 0, 90, 180, or 270 degrees respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oHkeNUOKiFbP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import functional\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "def rotate_img(img, rot):\n",
        "    if rot == 0: # 0 degrees rotation\n",
        "        return img\n",
        "    #######################################################################\n",
        "    #        TODO: Implement rotate_img() - return the rotated img        #\n",
        "    #######################################################################\n",
        "    if rot == 0:  # 0 degrees rotation\n",
        "        return img\n",
        "    elif rot == 1:  # 90 degrees rotation\n",
        "        return transforms.functional.rotate(img, 90)\n",
        "    elif rot == 2:  # 180 degrees rotation\n",
        "        return transforms.functional.rotate(img, 180)\n",
        "    elif rot == 3:  # 270 degrees rotation\n",
        "        return transforms.functional.rotate(img, 270)\n",
        "    else:\n",
        "        raise ValueError('rotation should be 0, 90, 180, or 270 degrees')\n",
        "\n",
        "    #######################################################################\n",
        "    #                           End of your code                          #\n",
        "    #######################################################################\n",
        "\n",
        "class CIFAR10Rotation(torchvision.datasets.CIFAR10):\n",
        "\n",
        "    def __init__(self, root, train, download, transform) -> None:\n",
        "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        image, cls_label = super().__getitem__(index)\n",
        "\n",
        "        # randomly select image rotation\n",
        "        rotation_label = random.choice([0, 1, 2, 3])\n",
        "        image_rotated = rotate_img(image, rotation_label)\n",
        "\n",
        "        rotation_label = torch.tensor(rotation_label).long()\n",
        "        return image, image_rotated, rotation_label, torch.tensor(cls_label).long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CCBSpNWpb8uw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26fe7383-b706-4b9f-b91d-52a935506801"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 80836316.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "trainset = CIFAR10Rotation(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = CIFAR10Rotation(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOCWMyGhVOJB"
      },
      "source": [
        "Show some example images and rotated images with labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "A9wN4BJWVMzB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "4e2b1814-353d-4c40-c120-20026c98b35b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class labels:  plane frog  dog   ship \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rotation labels:  270   90    0     270  \n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "rot_classes = ('0', '90', '180', '270')\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    # unnormalize\n",
        "    img = transforms.Normalize((0, 0, 0), (1/0.2023, 1/0.1994, 1/0.2010))(img)\n",
        "    img = transforms.Normalize((-0.4914, -0.4822, -0.4465), (1, 1, 1))(img)\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, rot_images, rot_labels, labels = next(dataiter)\n",
        "\n",
        "# print images and rotated images\n",
        "img_grid = imshow(torchvision.utils.make_grid(images[:4], padding=0))\n",
        "print('Class labels: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
        "img_grid = imshow(torchvision.utils.make_grid(rot_images[:4], padding=0))\n",
        "print('Rotation labels: ', ' '.join(f'{rot_classes[rot_labels[j]]:5s}' for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unCucbHexG4W"
      },
      "source": [
        "# Evaluation code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pptQRpqK0rOl"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def run_test(net, testloader, criterion, task):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    avg_test_loss = 0.0\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for images, images_rotated, labels, cls_labels in testloader:\n",
        "            if task == 'rotation':\n",
        "              images, labels = images_rotated.to(device), labels.to(device)\n",
        "            elif task == 'classification':\n",
        "              images, labels = images.to(device), cls_labels.to(device)\n",
        "            #######################################################################\n",
        "            # TODO: Calculate outputs by running images through the network       #\n",
        "            # The class with the highest energy is what we choose as prediction   #\n",
        "            #######################################################################\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            #######################################################################\n",
        "            #                           End of your code                          #\n",
        "            #######################################################################\n",
        "            avg_test_loss += criterion(outputs, labels)  / len(testloader)\n",
        "    print('TESTING:')\n",
        "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
        "    print(f'Average loss on the 10000 test images: {avg_test_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hf698c16A9k5"
      },
      "outputs": [],
      "source": [
        "def adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs=30):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    lr = init_lr * (0.1 ** (epoch // decay_epochs))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lYdnb1Wsta_"
      },
      "source": [
        "# Train a ResNet18 on the rotation task (9 points)\n",
        "\n",
        "In this section, we will train a ResNet18 model **from scratch** on the rotation task. The input is a rotated image and the model predicts the rotation label. See the Data Setup section for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "knAiwdURvBHk",
        "outputId": "8398ea2c-def4-4566-9bb3-7f62aec5758b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx3OZ6jD7YIt"
      },
      "source": [
        "### Notice: You should not use pretrained weights from ImageNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "235MEIUgsv65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb9e23c6-cf63-4759-bd33-cba23610e552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "net = resnet18(weights = None, num_classes=4) # Do not modify this line.\n",
        "net = net.to(device)\n",
        "print(net) # print your model and check the num_classes is correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Vuhiw0ZoszAd"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "################################################################################\n",
        "# TODO: Define loss and optmizer functions                                     #\n",
        "# Try any loss or optimizer function and learning rate to get better result    #\n",
        "# hint: torch.nn and torch.optim                                               #\n",
        "################################################################################\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "################################################################################\n",
        "#                               End of your code                               #\n",
        "################################################################################\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WleH-YBgs0rq"
      },
      "outputs": [],
      "source": [
        "# Both the self-supervised rotation task and supervised CIFAR10 classification are\n",
        "# trained with the CrossEntropyLoss, so we can use the training loop code.\n",
        "\n",
        "def train(net, criterion, optimizer, num_epochs, decay_epochs, init_lr, task):\n",
        "\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0.0\n",
        "        running_total = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        net.train()\n",
        "\n",
        "        for i, (imgs, imgs_rotated, rotation_label, cls_label) in enumerate(trainloader, 0):\n",
        "            adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs)\n",
        "            ######################################################################################################\n",
        "            # TODO: Set the data to the correct device; Different task will use different inputs and labels      #\n",
        "            # TODO: Zero the parameter gradients                                                                 #\n",
        "            # TODO: forward + backward + optimize                                                                #\n",
        "            # TODO: Get predicted results                                                                        #\n",
        "            ######################################################################################################\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if task == 'rotation':\n",
        "                # Move data to the correct device\n",
        "                imgs_rotated, rotation_label = imgs_rotated.to(device), rotation_label.to(device)\n",
        "                # For rotation task, use imgs_rotated as input\n",
        "                outputs = net(imgs_rotated)\n",
        "                loss = criterion(outputs, rotation_label)\n",
        "            elif task == 'classification':\n",
        "                # Move data to the correct device\n",
        "                imgs, cls_label = imgs.to(device), cls_label.to(device)\n",
        "                # For classification task, use imgs as input\n",
        "                outputs = net(imgs)\n",
        "                loss = criterion(outputs, cls_label)\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported task: {task}\")\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Get predicted results\n",
        "            _, predicted = outputs.max(1)\n",
        "            ######################################################################################################\n",
        "            #                               End of your code                                                     #\n",
        "            ######################################################################################################\n",
        "\n",
        "            # print statistics\n",
        "            print_freq = 100\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # calc acc\n",
        "            running_total += labels.size(0)\n",
        "            running_correct += (predicted == labels.to(device)[:predicted.size(0)]).sum().item()\n",
        "            #running_correct += (predicted == labels.to(device)).sum().item()\n",
        "\n",
        "            if i % print_freq == (print_freq - 1):    # print every 2000 mini-batches\n",
        "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.3f} acc: {100*running_correct / running_total:.2f} time: {time.time() - start_time:.2f}')\n",
        "                running_loss, running_correct, running_total = 0.0, 0.0, 0.0\n",
        "                start_time = time.time()\n",
        "        ######################################################################################################\n",
        "        # TODO: Run the run_test() function after each epoch; Set the model to the evaluation mode.          #\n",
        "        ######################################################################################################\n",
        "        run_test(net, testloader, criterion, task)\n",
        "        ######################################################################################################\n",
        "        #                               End of your code                                                     #\n",
        "        ######################################################################################################\n",
        "\n",
        "    print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2u4AsfAKtaQS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3def003-a3e5-4c46-c2d8-c818b1e0dbb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 1.061 acc: 9.57 time: 9.31\n",
            "[1,   200] loss: 1.052 acc: 9.53 time: 10.89\n",
            "[1,   300] loss: 1.029 acc: 9.46 time: 13.57\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 58.22 %\n",
            "Average loss on the 10000 test images: 0.996\n",
            "[2,   100] loss: 1.015 acc: 9.68 time: 9.45\n",
            "[2,   200] loss: 0.997 acc: 9.70 time: 10.08\n",
            "[2,   300] loss: 0.994 acc: 9.91 time: 8.78\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 59.31 %\n",
            "Average loss on the 10000 test images: 0.955\n",
            "[3,   100] loss: 0.968 acc: 9.94 time: 10.51\n",
            "[3,   200] loss: 0.950 acc: 9.70 time: 8.93\n",
            "[3,   300] loss: 0.956 acc: 10.11 time: 10.81\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 61.69 %\n",
            "Average loss on the 10000 test images: 0.912\n",
            "[4,   100] loss: 0.927 acc: 9.82 time: 9.62\n",
            "[4,   200] loss: 0.914 acc: 9.60 time: 9.97\n",
            "[4,   300] loss: 0.913 acc: 9.66 time: 8.81\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 61.24 %\n",
            "Average loss on the 10000 test images: 0.924\n",
            "[5,   100] loss: 0.899 acc: 9.94 time: 10.33\n",
            "[5,   200] loss: 0.896 acc: 9.77 time: 9.35\n",
            "[5,   300] loss: 0.882 acc: 9.81 time: 10.15\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 64.57 %\n",
            "Average loss on the 10000 test images: 0.850\n",
            "[6,   100] loss: 0.883 acc: 9.80 time: 10.63\n",
            "[6,   200] loss: 0.870 acc: 9.82 time: 9.36\n",
            "[6,   300] loss: 0.866 acc: 9.63 time: 9.44\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 64.83 %\n",
            "Average loss on the 10000 test images: 0.859\n",
            "[7,   100] loss: 0.862 acc: 9.90 time: 11.06\n",
            "[7,   200] loss: 0.850 acc: 9.91 time: 8.49\n",
            "[7,   300] loss: 0.843 acc: 10.20 time: 10.79\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 65.95 %\n",
            "Average loss on the 10000 test images: 0.820\n",
            "[8,   100] loss: 0.825 acc: 9.70 time: 10.28\n",
            "[8,   200] loss: 0.839 acc: 9.65 time: 9.92\n",
            "[8,   300] loss: 0.829 acc: 9.68 time: 8.77\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 66.17 %\n",
            "Average loss on the 10000 test images: 0.814\n",
            "[9,   100] loss: 0.815 acc: 9.93 time: 8.77\n",
            "[9,   200] loss: 0.825 acc: 9.89 time: 10.34\n",
            "[9,   300] loss: 0.803 acc: 9.96 time: 9.54\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 67.67 %\n",
            "Average loss on the 10000 test images: 0.788\n",
            "[10,   100] loss: 0.791 acc: 9.84 time: 14.27\n",
            "[10,   200] loss: 0.791 acc: 10.19 time: 9.72\n",
            "[10,   300] loss: 0.782 acc: 9.07 time: 9.05\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 68.61 %\n",
            "Average loss on the 10000 test images: 0.773\n",
            "[11,   100] loss: 0.779 acc: 9.91 time: 9.88\n",
            "[11,   200] loss: 0.763 acc: 9.66 time: 9.45\n",
            "[11,   300] loss: 0.775 acc: 9.80 time: 9.96\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 68.60 %\n",
            "Average loss on the 10000 test images: 0.768\n",
            "[12,   100] loss: 0.763 acc: 10.11 time: 10.18\n",
            "[12,   200] loss: 0.753 acc: 9.96 time: 9.92\n",
            "[12,   300] loss: 0.753 acc: 9.41 time: 8.72\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 71.37 %\n",
            "Average loss on the 10000 test images: 0.723\n",
            "[13,   100] loss: 0.748 acc: 9.69 time: 9.70\n",
            "[13,   200] loss: 0.740 acc: 10.16 time: 9.22\n",
            "[13,   300] loss: 0.739 acc: 9.46 time: 10.26\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 70.80 %\n",
            "Average loss on the 10000 test images: 0.726\n",
            "[14,   100] loss: 0.724 acc: 9.70 time: 10.83\n",
            "[14,   200] loss: 0.720 acc: 10.12 time: 9.55\n",
            "[14,   300] loss: 0.721 acc: 9.49 time: 9.19\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 72.29 %\n",
            "Average loss on the 10000 test images: 0.697\n",
            "[15,   100] loss: 0.708 acc: 10.03 time: 9.91\n",
            "[15,   200] loss: 0.711 acc: 9.62 time: 9.42\n",
            "[15,   300] loss: 0.707 acc: 9.65 time: 10.33\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 72.01 %\n",
            "Average loss on the 10000 test images: 0.697\n",
            "[16,   100] loss: 0.672 acc: 9.88 time: 10.66\n",
            "[16,   200] loss: 0.641 acc: 9.77 time: 10.08\n",
            "[16,   300] loss: 0.641 acc: 9.79 time: 9.68\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 75.00 %\n",
            "Average loss on the 10000 test images: 0.636\n",
            "[17,   100] loss: 0.635 acc: 9.97 time: 10.81\n",
            "[17,   200] loss: 0.619 acc: 9.88 time: 11.54\n",
            "[17,   300] loss: 0.621 acc: 9.69 time: 11.38\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 74.84 %\n",
            "Average loss on the 10000 test images: 0.634\n",
            "[18,   100] loss: 0.611 acc: 9.96 time: 8.20\n",
            "[18,   200] loss: 0.620 acc: 9.88 time: 10.91\n",
            "[18,   300] loss: 0.621 acc: 9.80 time: 8.58\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 75.33 %\n",
            "Average loss on the 10000 test images: 0.629\n",
            "[19,   100] loss: 0.601 acc: 9.98 time: 11.22\n",
            "[19,   200] loss: 0.605 acc: 10.06 time: 7.99\n",
            "[19,   300] loss: 0.607 acc: 9.63 time: 10.85\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 75.42 %\n",
            "Average loss on the 10000 test images: 0.616\n",
            "[20,   100] loss: 0.595 acc: 9.98 time: 8.83\n",
            "[20,   200] loss: 0.604 acc: 10.01 time: 10.73\n",
            "[20,   300] loss: 0.600 acc: 9.97 time: 8.14\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 75.87 %\n",
            "Average loss on the 10000 test images: 0.613\n",
            "[21,   100] loss: 0.608 acc: 9.55 time: 11.31\n",
            "[21,   200] loss: 0.602 acc: 10.05 time: 7.77\n",
            "[21,   300] loss: 0.591 acc: 9.36 time: 11.06\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.07 %\n",
            "Average loss on the 10000 test images: 0.612\n",
            "[22,   100] loss: 0.589 acc: 9.96 time: 8.32\n",
            "[22,   200] loss: 0.587 acc: 9.80 time: 10.81\n",
            "[22,   300] loss: 0.586 acc: 10.02 time: 7.77\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.46 %\n",
            "Average loss on the 10000 test images: 0.605\n",
            "[23,   100] loss: 0.581 acc: 9.81 time: 11.05\n",
            "[23,   200] loss: 0.586 acc: 9.62 time: 8.07\n",
            "[23,   300] loss: 0.589 acc: 10.51 time: 10.90\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.05 %\n",
            "Average loss on the 10000 test images: 0.605\n",
            "[24,   100] loss: 0.593 acc: 9.37 time: 8.33\n",
            "[24,   200] loss: 0.594 acc: 9.77 time: 10.94\n",
            "[24,   300] loss: 0.578 acc: 9.62 time: 10.02\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.53 %\n",
            "Average loss on the 10000 test images: 0.601\n",
            "[25,   100] loss: 0.584 acc: 9.80 time: 11.05\n",
            "[25,   200] loss: 0.576 acc: 9.40 time: 8.76\n",
            "[25,   300] loss: 0.570 acc: 9.70 time: 10.05\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.52 %\n",
            "Average loss on the 10000 test images: 0.601\n",
            "[26,   100] loss: 0.565 acc: 9.87 time: 11.88\n",
            "[26,   200] loss: 0.576 acc: 9.70 time: 10.57\n",
            "[26,   300] loss: 0.583 acc: 9.39 time: 9.44\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.69 %\n",
            "Average loss on the 10000 test images: 0.598\n",
            "[27,   100] loss: 0.568 acc: 9.47 time: 15.03\n",
            "[27,   200] loss: 0.572 acc: 9.70 time: 9.34\n",
            "[27,   300] loss: 0.574 acc: 9.70 time: 9.21\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.11 %\n",
            "Average loss on the 10000 test images: 0.594\n",
            "[28,   100] loss: 0.562 acc: 9.73 time: 8.65\n",
            "[28,   200] loss: 0.579 acc: 9.52 time: 10.44\n",
            "[28,   300] loss: 0.568 acc: 9.62 time: 9.53\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.24 %\n",
            "Average loss on the 10000 test images: 0.586\n",
            "[29,   100] loss: 0.562 acc: 9.78 time: 12.27\n",
            "[29,   200] loss: 0.575 acc: 9.77 time: 10.41\n",
            "[29,   300] loss: 0.574 acc: 10.03 time: 8.36\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.77 %\n",
            "Average loss on the 10000 test images: 0.598\n",
            "[30,   100] loss: 0.554 acc: 9.51 time: 10.56\n",
            "[30,   200] loss: 0.553 acc: 9.71 time: 9.07\n",
            "[30,   300] loss: 0.561 acc: 10.06 time: 11.39\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.04 %\n",
            "Average loss on the 10000 test images: 0.592\n",
            "[31,   100] loss: 0.560 acc: 9.96 time: 9.03\n",
            "[31,   200] loss: 0.552 acc: 10.05 time: 11.17\n",
            "[31,   300] loss: 0.555 acc: 9.60 time: 8.05\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.51 %\n",
            "Average loss on the 10000 test images: 0.586\n",
            "[32,   100] loss: 0.557 acc: 9.84 time: 10.87\n",
            "[32,   200] loss: 0.547 acc: 9.82 time: 8.06\n",
            "[32,   300] loss: 0.554 acc: 9.27 time: 10.84\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.65 %\n",
            "Average loss on the 10000 test images: 0.590\n",
            "[33,   100] loss: 0.550 acc: 9.60 time: 8.82\n",
            "[33,   200] loss: 0.557 acc: 9.91 time: 10.83\n",
            "[33,   300] loss: 0.543 acc: 9.84 time: 7.75\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.37 %\n",
            "Average loss on the 10000 test images: 0.585\n",
            "[34,   100] loss: 0.561 acc: 9.67 time: 11.12\n",
            "[34,   200] loss: 0.548 acc: 10.10 time: 7.98\n",
            "[34,   300] loss: 0.537 acc: 9.71 time: 13.02\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.57 %\n",
            "Average loss on the 10000 test images: 0.584\n",
            "[35,   100] loss: 0.535 acc: 9.59 time: 8.05\n",
            "[35,   200] loss: 0.549 acc: 9.52 time: 10.90\n",
            "[35,   300] loss: 0.546 acc: 9.42 time: 9.23\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.58 %\n",
            "Average loss on the 10000 test images: 0.587\n",
            "[36,   100] loss: 0.540 acc: 9.83 time: 11.11\n",
            "[36,   200] loss: 0.551 acc: 9.48 time: 7.93\n",
            "[36,   300] loss: 0.542 acc: 9.99 time: 11.01\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.36 %\n",
            "Average loss on the 10000 test images: 0.589\n",
            "[37,   100] loss: 0.546 acc: 9.62 time: 8.25\n",
            "[37,   200] loss: 0.552 acc: 9.80 time: 10.70\n",
            "[37,   300] loss: 0.539 acc: 9.48 time: 7.72\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.23 %\n",
            "Average loss on the 10000 test images: 0.584\n",
            "[38,   100] loss: 0.544 acc: 9.66 time: 11.11\n",
            "[38,   200] loss: 0.546 acc: 9.73 time: 7.76\n",
            "[38,   300] loss: 0.541 acc: 10.03 time: 10.94\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.39 %\n",
            "Average loss on the 10000 test images: 0.583\n",
            "[39,   100] loss: 0.546 acc: 9.42 time: 9.13\n",
            "[39,   200] loss: 0.538 acc: 9.80 time: 10.89\n",
            "[39,   300] loss: 0.542 acc: 9.68 time: 8.22\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.74 %\n",
            "Average loss on the 10000 test images: 0.576\n",
            "[40,   100] loss: 0.547 acc: 9.66 time: 11.09\n",
            "[40,   200] loss: 0.538 acc: 9.52 time: 8.27\n",
            "[40,   300] loss: 0.546 acc: 9.92 time: 11.29\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.57 %\n",
            "Average loss on the 10000 test images: 0.581\n",
            "[41,   100] loss: 0.542 acc: 9.69 time: 9.07\n",
            "[41,   200] loss: 0.550 acc: 9.78 time: 11.09\n",
            "[41,   300] loss: 0.534 acc: 9.89 time: 7.84\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.67 %\n",
            "Average loss on the 10000 test images: 0.582\n",
            "[42,   100] loss: 0.541 acc: 10.05 time: 11.19\n",
            "[42,   200] loss: 0.552 acc: 9.58 time: 8.15\n",
            "[42,   300] loss: 0.543 acc: 9.63 time: 11.06\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.95 %\n",
            "Average loss on the 10000 test images: 0.576\n",
            "[43,   100] loss: 0.538 acc: 9.97 time: 10.70\n",
            "[43,   200] loss: 0.537 acc: 10.19 time: 12.02\n",
            "[43,   300] loss: 0.544 acc: 9.84 time: 8.46\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.86 %\n",
            "Average loss on the 10000 test images: 0.571\n",
            "[44,   100] loss: 0.536 acc: 10.03 time: 13.67\n",
            "[44,   200] loss: 0.539 acc: 10.02 time: 9.43\n",
            "[44,   300] loss: 0.544 acc: 9.47 time: 10.50\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.36 %\n",
            "Average loss on the 10000 test images: 0.575\n",
            "[45,   100] loss: 0.529 acc: 9.42 time: 9.67\n",
            "[45,   200] loss: 0.540 acc: 10.09 time: 9.86\n",
            "[45,   300] loss: 0.550 acc: 9.73 time: 10.05\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.93 %\n",
            "Average loss on the 10000 test images: 0.571\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(net, criterion, optimizer, num_epochs=45, decay_epochs=15, init_lr=0.01, task='rotation')\n",
        "################################\n",
        "#     TODO: Save the model     #\n",
        "################################\n",
        "torch.save(net.state_dict(), 'model.pt')\n",
        "################################\n",
        "#      End of your code        #\n",
        "################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLLMRTS9rTnk"
      },
      "source": [
        "## Fine-tuning on the pre-trained model (9 points)\n",
        "\n",
        "In this section, we will load the ResNet18 model pre-trained on the rotation task and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer.\n",
        "\n",
        "**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4nX4ExlrymI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd0c7b0c-7cff-4dd3-fdc6-4d249b46d185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "#####################################################\n",
        "#     TODO: Load the pre-trained ResNet18 model     #\n",
        "#####################################################\n",
        "ckpt = torch.load('model.pt')\n",
        "net.load_state_dict(ckpt)\n",
        "net.fc = nn.Linear(512, 10)\n",
        "net = net.to(device)\n",
        "print(net) # print your model and check the num_classes is correct\n",
        "####################################################\n",
        "#                End of your code                  #\n",
        "####################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kD44g-TxwYdU"
      },
      "outputs": [],
      "source": [
        "#################################################################################################\n",
        "#   TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable     #\n",
        "#################################################################################################\n",
        "for name, param in net.named_parameters():\n",
        "    if 'layer4' in name or 'fc' in name:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "#################################################################################################\n",
        "#                                          End of your code                                     #\n",
        "#################################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T5DX0efr4fh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0388a81e-c875-4476-a77b-ee01e34353fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "\t layer4.0.conv1.weight\n",
            "\t layer4.0.bn1.weight\n",
            "\t layer4.0.bn1.bias\n",
            "\t layer4.0.conv2.weight\n",
            "\t layer4.0.bn2.weight\n",
            "\t layer4.0.bn2.bias\n",
            "\t layer4.0.downsample.0.weight\n",
            "\t layer4.0.downsample.1.weight\n",
            "\t layer4.0.downsample.1.bias\n",
            "\t layer4.1.conv1.weight\n",
            "\t layer4.1.bn1.weight\n",
            "\t layer4.1.bn1.bias\n",
            "\t layer4.1.conv2.weight\n",
            "\t layer4.1.bn2.weight\n",
            "\t layer4.1.bn2.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ]
        }
      ],
      "source": [
        "# Print all the trainable parameters\n",
        "params_to_update = net.parameters()\n",
        "print(\"Params to learn:\")\n",
        "params_to_update = []\n",
        "for name,param in net.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb032dG700ph"
      },
      "outputs": [],
      "source": [
        "# TODO: Define criterion and optimizer\n",
        "# Note that your optimizer only needs to update the parameters that are trainable.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params_to_update, lr=0.1, momentum=0.9)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vLSwOo6sBjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa3ed890-ae62-4995-82a6-ec014c39bfc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 1.949 acc: 10.45 time: 9.14\n",
            "[1,   200] loss: 1.886 acc: 10.35 time: 9.40\n",
            "[1,   300] loss: 1.848 acc: 10.07 time: 7.64\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 32.70 %\n",
            "Average loss on the 10000 test images: 1.834\n",
            "[2,   100] loss: 1.773 acc: 10.09 time: 9.36\n",
            "[2,   200] loss: 1.771 acc: 10.94 time: 7.74\n",
            "[2,   300] loss: 1.734 acc: 10.04 time: 8.86\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 35.05 %\n",
            "Average loss on the 10000 test images: 1.745\n",
            "[3,   100] loss: 1.735 acc: 10.33 time: 11.48\n",
            "[3,   200] loss: 1.692 acc: 10.02 time: 7.42\n",
            "[3,   300] loss: 1.704 acc: 10.56 time: 9.51\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 37.49 %\n",
            "Average loss on the 10000 test images: 1.714\n",
            "[4,   100] loss: 1.678 acc: 10.57 time: 7.63\n",
            "[4,   200] loss: 1.675 acc: 10.29 time: 9.73\n",
            "[4,   300] loss: 1.674 acc: 10.19 time: 7.36\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 39.39 %\n",
            "Average loss on the 10000 test images: 1.667\n",
            "[5,   100] loss: 1.632 acc: 9.41 time: 8.90\n",
            "[5,   200] loss: 1.651 acc: 10.03 time: 8.29\n",
            "[5,   300] loss: 1.651 acc: 10.27 time: 8.49\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 41.74 %\n",
            "Average loss on the 10000 test images: 1.621\n",
            "[6,   100] loss: 1.607 acc: 10.26 time: 10.32\n",
            "[6,   200] loss: 1.611 acc: 10.04 time: 7.04\n",
            "[6,   300] loss: 1.603 acc: 10.34 time: 9.88\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 40.66 %\n",
            "Average loss on the 10000 test images: 1.613\n",
            "[7,   100] loss: 1.569 acc: 10.07 time: 8.26\n",
            "[7,   200] loss: 1.552 acc: 10.23 time: 8.58\n",
            "[7,   300] loss: 1.551 acc: 9.74 time: 8.37\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 43.35 %\n",
            "Average loss on the 10000 test images: 1.550\n",
            "[8,   100] loss: 1.538 acc: 10.40 time: 7.31\n",
            "[8,   200] loss: 1.541 acc: 10.18 time: 10.00\n",
            "[8,   300] loss: 1.523 acc: 10.33 time: 7.42\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 44.52 %\n",
            "Average loss on the 10000 test images: 1.525\n",
            "[9,   100] loss: 1.509 acc: 9.98 time: 8.92\n",
            "[9,   200] loss: 1.514 acc: 9.85 time: 8.09\n",
            "[9,   300] loss: 1.493 acc: 10.62 time: 8.82\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 44.18 %\n",
            "Average loss on the 10000 test images: 1.523\n",
            "[10,   100] loss: 1.494 acc: 10.07 time: 9.92\n",
            "[10,   200] loss: 1.491 acc: 10.41 time: 7.19\n",
            "[10,   300] loss: 1.478 acc: 10.00 time: 9.86\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 43.62 %\n",
            "Average loss on the 10000 test images: 1.525\n",
            "[11,   100] loss: 1.430 acc: 10.23 time: 10.54\n",
            "[11,   200] loss: 1.431 acc: 9.98 time: 7.33\n",
            "[11,   300] loss: 1.412 acc: 10.27 time: 9.56\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 47.16 %\n",
            "Average loss on the 10000 test images: 1.439\n",
            "[12,   100] loss: 1.419 acc: 9.53 time: 7.73\n",
            "[12,   200] loss: 1.408 acc: 10.30 time: 9.61\n",
            "[12,   300] loss: 1.405 acc: 10.04 time: 7.27\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 47.63 %\n",
            "Average loss on the 10000 test images: 1.431\n",
            "[13,   100] loss: 1.388 acc: 10.51 time: 7.55\n",
            "[13,   200] loss: 1.406 acc: 9.96 time: 9.47\n",
            "[13,   300] loss: 1.410 acc: 10.26 time: 7.18\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 47.96 %\n",
            "Average loss on the 10000 test images: 1.424\n",
            "[14,   100] loss: 1.405 acc: 9.88 time: 9.78\n",
            "[14,   200] loss: 1.394 acc: 9.47 time: 7.47\n",
            "[14,   300] loss: 1.395 acc: 10.39 time: 9.70\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 48.57 %\n",
            "Average loss on the 10000 test images: 1.420\n",
            "[15,   100] loss: 1.378 acc: 10.12 time: 9.65\n",
            "[15,   200] loss: 1.390 acc: 10.28 time: 7.67\n",
            "[15,   300] loss: 1.388 acc: 10.09 time: 9.63\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 48.62 %\n",
            "Average loss on the 10000 test images: 1.414\n",
            "[16,   100] loss: 1.381 acc: 10.30 time: 7.48\n",
            "[16,   200] loss: 1.377 acc: 9.98 time: 9.86\n",
            "[16,   300] loss: 1.392 acc: 9.89 time: 7.26\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 48.89 %\n",
            "Average loss on the 10000 test images: 1.405\n",
            "[17,   100] loss: 1.407 acc: 10.15 time: 8.02\n",
            "[17,   200] loss: 1.367 acc: 10.05 time: 9.33\n",
            "[17,   300] loss: 1.391 acc: 9.91 time: 7.76\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 48.93 %\n",
            "Average loss on the 10000 test images: 1.404\n",
            "[18,   100] loss: 1.383 acc: 10.25 time: 13.02\n",
            "[18,   200] loss: 1.389 acc: 9.73 time: 7.44\n",
            "[18,   300] loss: 1.383 acc: 10.26 time: 9.86\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 48.90 %\n",
            "Average loss on the 10000 test images: 1.395\n",
            "[19,   100] loss: 1.377 acc: 9.67 time: 7.88\n",
            "[19,   200] loss: 1.377 acc: 10.04 time: 9.68\n",
            "[19,   300] loss: 1.378 acc: 9.95 time: 7.69\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 49.16 %\n",
            "Average loss on the 10000 test images: 1.394\n",
            "[20,   100] loss: 1.376 acc: 10.42 time: 8.91\n",
            "[20,   200] loss: 1.380 acc: 9.74 time: 11.80\n",
            "[20,   300] loss: 1.377 acc: 9.71 time: 7.37\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 49.44 %\n",
            "Average loss on the 10000 test images: 1.392\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.1, task='classification')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghPNhcJBrcNj"
      },
      "source": [
        "## Fine-tuning on the randomly initialized model (9 points)\n",
        "In this section, we will randomly initialize a ResNet18 model and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RfXAh9vxXRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59ec3ec7-fd6c-4fab-8ffa-2d0b73980012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "#################################################\n",
        "# TODO: Randomly initialize a ResNet18 model    #\n",
        "#################################################\n",
        "net = resnet18(weights=None, num_classes=10)\n",
        "net = net.to(device)\n",
        "print(net) # print your model and check the num_classes is correct\n",
        "#################################################\n",
        "#              End of your code                 #\n",
        "#################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpx-SYAizt4p"
      },
      "outputs": [],
      "source": [
        "#################################################################################################\n",
        "# TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable       #\n",
        "# To do this, you should set requires_grad=False for the frozen layers.                         #\n",
        "#################################################################################################\n",
        "for name, param in net.named_parameters():\n",
        "    if 'layer4' in name or 'fc' in name:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "#################################################################################################\n",
        "#                                          End of your code                                     #\n",
        "#################################################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUFWizbHxgm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee6af18-2f37-4c81-a61f-9674ea15c43d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "\t layer4.0.conv1.weight\n",
            "\t layer4.0.bn1.weight\n",
            "\t layer4.0.bn1.bias\n",
            "\t layer4.0.conv2.weight\n",
            "\t layer4.0.bn2.weight\n",
            "\t layer4.0.bn2.bias\n",
            "\t layer4.0.downsample.0.weight\n",
            "\t layer4.0.downsample.1.weight\n",
            "\t layer4.0.downsample.1.bias\n",
            "\t layer4.1.conv1.weight\n",
            "\t layer4.1.bn1.weight\n",
            "\t layer4.1.bn1.bias\n",
            "\t layer4.1.conv2.weight\n",
            "\t layer4.1.bn2.weight\n",
            "\t layer4.1.bn2.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ]
        }
      ],
      "source": [
        "# Print all the trainable parameters\n",
        "params_to_update = net.parameters()\n",
        "print(\"Params to learn:\")\n",
        "params_to_update = []\n",
        "for name,param in net.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxFrGj091AN_"
      },
      "outputs": [],
      "source": [
        "# TODO: Define criterion and optimizer\n",
        "# Note that your optimizer only needs to update the parameters that are trainable.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params_to_update, lr=0.1, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzRVy0MZxpoL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cea53e1-c5cc-4bd5-ac81-363ee03a3998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 1.586 acc: 10.27 time: 6.76\n",
            "[1,   200] loss: 1.650 acc: 9.96 time: 8.43\n",
            "[1,   300] loss: 1.635 acc: 10.45 time: 9.23\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 41.49 %\n",
            "Average loss on the 10000 test images: 1.651\n",
            "[2,   100] loss: 1.634 acc: 9.67 time: 8.65\n",
            "[2,   200] loss: 1.629 acc: 10.16 time: 6.57\n",
            "[2,   300] loss: 1.635 acc: 10.16 time: 10.40\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 42.60 %\n",
            "Average loss on the 10000 test images: 1.632\n",
            "[3,   100] loss: 1.623 acc: 9.93 time: 7.44\n",
            "[3,   200] loss: 1.614 acc: 9.79 time: 7.72\n",
            "[3,   300] loss: 1.609 acc: 10.38 time: 7.27\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 42.35 %\n",
            "Average loss on the 10000 test images: 1.639\n",
            "[4,   100] loss: 1.595 acc: 9.74 time: 6.77\n",
            "[4,   200] loss: 1.622 acc: 9.85 time: 8.08\n",
            "[4,   300] loss: 1.607 acc: 10.01 time: 6.67\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 42.77 %\n",
            "Average loss on the 10000 test images: 1.618\n",
            "[5,   100] loss: 1.598 acc: 10.24 time: 8.47\n",
            "[5,   200] loss: 1.588 acc: 10.10 time: 6.46\n",
            "[5,   300] loss: 1.624 acc: 10.33 time: 8.38\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 43.27 %\n",
            "Average loss on the 10000 test images: 1.606\n",
            "[6,   100] loss: 1.593 acc: 9.98 time: 7.75\n",
            "[6,   200] loss: 1.591 acc: 10.00 time: 7.46\n",
            "[6,   300] loss: 1.594 acc: 9.62 time: 7.44\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 43.83 %\n",
            "Average loss on the 10000 test images: 1.595\n",
            "[7,   100] loss: 1.592 acc: 10.00 time: 6.69\n",
            "[7,   200] loss: 1.576 acc: 10.02 time: 8.49\n",
            "[7,   300] loss: 1.587 acc: 10.42 time: 6.65\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 43.51 %\n",
            "Average loss on the 10000 test images: 1.600\n",
            "[8,   100] loss: 1.577 acc: 10.48 time: 8.35\n",
            "[8,   200] loss: 1.575 acc: 10.24 time: 6.59\n",
            "[8,   300] loss: 1.582 acc: 10.10 time: 8.32\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 42.86 %\n",
            "Average loss on the 10000 test images: 1.609\n",
            "[9,   100] loss: 1.567 acc: 10.52 time: 8.09\n",
            "[9,   200] loss: 1.571 acc: 9.96 time: 7.69\n",
            "[9,   300] loss: 1.578 acc: 9.92 time: 7.56\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 43.84 %\n",
            "Average loss on the 10000 test images: 1.588\n",
            "[10,   100] loss: 1.569 acc: 10.36 time: 6.51\n",
            "[10,   200] loss: 1.558 acc: 10.29 time: 8.38\n",
            "[10,   300] loss: 1.573 acc: 10.26 time: 6.57\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 43.44 %\n",
            "Average loss on the 10000 test images: 1.597\n",
            "[11,   100] loss: 1.553 acc: 9.68 time: 8.11\n",
            "[11,   200] loss: 1.525 acc: 9.91 time: 6.91\n",
            "[11,   300] loss: 1.520 acc: 10.13 time: 7.58\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 44.79 %\n",
            "Average loss on the 10000 test images: 1.568\n",
            "[12,   100] loss: 1.525 acc: 10.12 time: 8.54\n",
            "[12,   200] loss: 1.512 acc: 10.27 time: 7.74\n",
            "[12,   300] loss: 1.515 acc: 10.03 time: 8.72\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 44.92 %\n",
            "Average loss on the 10000 test images: 1.556\n",
            "[13,   100] loss: 1.500 acc: 10.34 time: 6.68\n",
            "[13,   200] loss: 1.505 acc: 9.66 time: 8.09\n",
            "[13,   300] loss: 1.519 acc: 10.39 time: 8.13\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.32 %\n",
            "Average loss on the 10000 test images: 1.553\n",
            "[14,   100] loss: 1.503 acc: 10.20 time: 8.14\n",
            "[14,   200] loss: 1.491 acc: 10.06 time: 6.74\n",
            "[14,   300] loss: 1.507 acc: 10.06 time: 8.19\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.27 %\n",
            "Average loss on the 10000 test images: 1.555\n",
            "[15,   100] loss: 1.492 acc: 10.12 time: 8.36\n",
            "[15,   200] loss: 1.509 acc: 10.23 time: 6.46\n",
            "[15,   300] loss: 1.497 acc: 10.49 time: 8.32\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.26 %\n",
            "Average loss on the 10000 test images: 1.549\n",
            "[16,   100] loss: 1.498 acc: 9.76 time: 6.95\n",
            "[16,   200] loss: 1.506 acc: 10.10 time: 8.17\n",
            "[16,   300] loss: 1.485 acc: 10.27 time: 6.52\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.22 %\n",
            "Average loss on the 10000 test images: 1.547\n",
            "[17,   100] loss: 1.486 acc: 10.08 time: 6.99\n",
            "[17,   200] loss: 1.493 acc: 9.98 time: 7.79\n",
            "[17,   300] loss: 1.499 acc: 10.12 time: 6.93\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.45 %\n",
            "Average loss on the 10000 test images: 1.547\n",
            "[18,   100] loss: 1.491 acc: 10.15 time: 8.27\n",
            "[18,   200] loss: 1.489 acc: 9.92 time: 6.56\n",
            "[18,   300] loss: 1.484 acc: 9.72 time: 8.12\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.70 %\n",
            "Average loss on the 10000 test images: 1.545\n",
            "[19,   100] loss: 1.479 acc: 10.12 time: 7.51\n",
            "[19,   200] loss: 1.477 acc: 10.17 time: 7.59\n",
            "[19,   300] loss: 1.494 acc: 9.76 time: 7.20\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.48 %\n",
            "Average loss on the 10000 test images: 1.540\n",
            "[20,   100] loss: 1.483 acc: 9.68 time: 6.73\n",
            "[20,   200] loss: 1.481 acc: 10.14 time: 8.19\n",
            "[20,   300] loss: 1.494 acc: 9.82 time: 6.34\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.82 %\n",
            "Average loss on the 10000 test images: 1.539\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.1, task='classification')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcN54tcNN15U"
      },
      "source": [
        "## Supervised training on the pre-trained model (9 points)\n",
        "In this section, we will load the ResNet18 model pre-trained on the rotation task and re-train the whole model on the classification task.\n",
        "\n",
        "**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9xR9h_S1N6Xi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "422483c4-d5bd-4048-dc23-caa1cee3b214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "#####################################################\n",
        "#     TODO: Load the pre-trained ResNet18 model     #\n",
        "#####################################################\n",
        "ckpt = torch.load('model.pt')\n",
        "net.load_state_dict(ckpt)\n",
        "net.fc = nn.Linear(512, 10)\n",
        "net = net.to(device)\n",
        "print(net) # print your model and check the num_classes is correct\n",
        "#####################################################\n",
        "#                End of your code                   #\n",
        "#####################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gGozc2cM0ADw"
      },
      "outputs": [],
      "source": [
        "# TODO: Define criterion and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JGWW7gzCz_Bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9154e42-09df-49d5-ff8b-467e3c39a604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 1.141 acc: 9.93 time: 9.30\n",
            "[1,   200] loss: 1.141 acc: 10.26 time: 8.80\n",
            "[1,   300] loss: 1.124 acc: 10.27 time: 8.80\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 58.98 %\n",
            "Average loss on the 10000 test images: 1.139\n",
            "[2,   100] loss: 1.096 acc: 9.85 time: 7.67\n",
            "[2,   200] loss: 1.110 acc: 10.02 time: 10.13\n",
            "[2,   300] loss: 1.076 acc: 9.84 time: 7.64\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 59.25 %\n",
            "Average loss on the 10000 test images: 1.143\n",
            "[3,   100] loss: 1.077 acc: 9.98 time: 10.37\n",
            "[3,   200] loss: 1.076 acc: 9.48 time: 7.52\n",
            "[3,   300] loss: 1.080 acc: 10.30 time: 10.04\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 61.30 %\n",
            "Average loss on the 10000 test images: 1.092\n",
            "[4,   100] loss: 1.055 acc: 9.77 time: 9.33\n",
            "[4,   200] loss: 1.022 acc: 10.15 time: 9.17\n",
            "[4,   300] loss: 1.032 acc: 9.99 time: 8.67\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 62.23 %\n",
            "Average loss on the 10000 test images: 1.059\n",
            "[5,   100] loss: 1.032 acc: 10.37 time: 7.86\n",
            "[5,   200] loss: 1.024 acc: 10.20 time: 10.22\n",
            "[5,   300] loss: 1.018 acc: 10.03 time: 8.26\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 62.74 %\n",
            "Average loss on the 10000 test images: 1.050\n",
            "[6,   100] loss: 1.000 acc: 9.84 time: 10.81\n",
            "[6,   200] loss: 1.000 acc: 9.85 time: 10.85\n",
            "[6,   300] loss: 0.985 acc: 9.91 time: 9.41\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 64.15 %\n",
            "Average loss on the 10000 test images: 1.009\n",
            "[7,   100] loss: 0.972 acc: 10.46 time: 8.46\n",
            "[7,   200] loss: 0.972 acc: 10.24 time: 8.81\n",
            "[7,   300] loss: 0.976 acc: 10.24 time: 9.54\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 64.63 %\n",
            "Average loss on the 10000 test images: 0.993\n",
            "[8,   100] loss: 0.948 acc: 10.29 time: 9.65\n",
            "[8,   200] loss: 0.967 acc: 9.99 time: 8.70\n",
            "[8,   300] loss: 0.963 acc: 9.97 time: 8.58\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 64.75 %\n",
            "Average loss on the 10000 test images: 0.995\n",
            "[9,   100] loss: 0.925 acc: 10.66 time: 8.14\n",
            "[9,   200] loss: 0.949 acc: 9.90 time: 9.05\n",
            "[9,   300] loss: 0.948 acc: 9.83 time: 11.01\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 65.75 %\n",
            "Average loss on the 10000 test images: 0.961\n",
            "[10,   100] loss: 0.928 acc: 10.55 time: 9.87\n",
            "[10,   200] loss: 0.933 acc: 9.79 time: 7.67\n",
            "[10,   300] loss: 0.917 acc: 9.64 time: 9.06\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 66.56 %\n",
            "Average loss on the 10000 test images: 0.946\n",
            "[11,   100] loss: 0.877 acc: 10.20 time: 7.68\n",
            "[11,   200] loss: 0.861 acc: 9.82 time: 9.53\n",
            "[11,   300] loss: 0.870 acc: 9.92 time: 8.15\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 67.46 %\n",
            "Average loss on the 10000 test images: 0.921\n",
            "[12,   100] loss: 0.864 acc: 9.96 time: 9.74\n",
            "[12,   200] loss: 0.863 acc: 10.36 time: 7.89\n",
            "[12,   300] loss: 0.858 acc: 10.02 time: 9.49\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 67.75 %\n",
            "Average loss on the 10000 test images: 0.917\n",
            "[13,   100] loss: 0.855 acc: 10.31 time: 7.56\n",
            "[13,   200] loss: 0.858 acc: 10.17 time: 9.46\n",
            "[13,   300] loss: 0.855 acc: 10.28 time: 7.76\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 67.68 %\n",
            "Average loss on the 10000 test images: 0.917\n",
            "[14,   100] loss: 0.853 acc: 10.20 time: 9.77\n",
            "[14,   200] loss: 0.868 acc: 9.66 time: 7.43\n",
            "[14,   300] loss: 0.849 acc: 10.10 time: 9.53\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 67.69 %\n",
            "Average loss on the 10000 test images: 0.918\n",
            "[15,   100] loss: 0.846 acc: 9.77 time: 7.42\n",
            "[15,   200] loss: 0.871 acc: 10.17 time: 9.60\n",
            "[15,   300] loss: 0.858 acc: 9.53 time: 7.50\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 67.74 %\n",
            "Average loss on the 10000 test images: 0.916\n",
            "[16,   100] loss: 0.866 acc: 10.02 time: 9.69\n",
            "[16,   200] loss: 0.857 acc: 9.88 time: 7.47\n",
            "[16,   300] loss: 0.841 acc: 10.24 time: 9.72\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 68.07 %\n",
            "Average loss on the 10000 test images: 0.912\n",
            "[17,   100] loss: 0.835 acc: 9.73 time: 9.83\n",
            "[17,   200] loss: 0.837 acc: 10.26 time: 9.52\n",
            "[17,   300] loss: 0.868 acc: 10.08 time: 7.40\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 67.95 %\n",
            "Average loss on the 10000 test images: 0.914\n",
            "[18,   100] loss: 0.848 acc: 9.73 time: 9.86\n",
            "[18,   200] loss: 0.840 acc: 9.76 time: 7.77\n",
            "[18,   300] loss: 0.859 acc: 10.43 time: 9.85\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 67.81 %\n",
            "Average loss on the 10000 test images: 0.911\n",
            "[19,   100] loss: 0.846 acc: 9.70 time: 7.83\n",
            "[19,   200] loss: 0.837 acc: 9.47 time: 9.88\n",
            "[19,   300] loss: 0.849 acc: 10.04 time: 9.76\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 67.84 %\n",
            "Average loss on the 10000 test images: 0.914\n",
            "[20,   100] loss: 0.846 acc: 10.00 time: 9.87\n",
            "[20,   200] loss: 0.857 acc: 10.48 time: 7.50\n",
            "[20,   300] loss: 0.860 acc: 10.04 time: 9.70\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 67.94 %\n",
            "Average loss on the 10000 test images: 0.909\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.1, task='classification')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjVTp9jhefTi"
      },
      "source": [
        "## Supervised training on the randomly initialized model (9 points)\n",
        "In this section, we will randomly initialize a ResNet18 model and re-train the whole model on the classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEjy8TBieeLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0da2dc1-7dd8-4873-e404-3e98d2c812ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "#################################################\n",
        "# TODO: Randomly initialize a ResNet18 model    #\n",
        "#################################################\n",
        "net = resnet18(weights=None, num_classes=10)\n",
        "net = net.to(device)\n",
        "print(net) # print your model and check the num_classes is correct\n",
        "#################################################\n",
        "#              End of your code                 #\n",
        "#################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEY90pK_0ZAm"
      },
      "outputs": [],
      "source": [
        "# TODO: Define criterion and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMDwelhY0auO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d46c729-27e6-4a78-ed3b-0f9fce2f26b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 1.999 acc: 10.26 time: 17.28\n",
            "[1,   200] loss: 1.728 acc: 10.05 time: 10.00\n",
            "[1,   300] loss: 1.579 acc: 10.00 time: 8.26\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 49.51 %\n",
            "Average loss on the 10000 test images: 1.389\n",
            "[2,   100] loss: 1.436 acc: 9.73 time: 8.72\n",
            "[2,   200] loss: 1.351 acc: 9.71 time: 10.36\n",
            "[2,   300] loss: 1.322 acc: 10.11 time: 10.74\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 57.21 %\n",
            "Average loss on the 10000 test images: 1.181\n",
            "[3,   100] loss: 1.230 acc: 10.23 time: 11.44\n",
            "[3,   200] loss: 1.175 acc: 9.95 time: 7.98\n",
            "[3,   300] loss: 1.178 acc: 10.21 time: 12.58\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 61.77 %\n",
            "Average loss on the 10000 test images: 1.078\n",
            "[4,   100] loss: 1.091 acc: 10.52 time: 8.06\n",
            "[4,   200] loss: 1.085 acc: 9.88 time: 10.73\n",
            "[4,   300] loss: 1.047 acc: 10.16 time: 8.33\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 64.13 %\n",
            "Average loss on the 10000 test images: 1.017\n",
            "[5,   100] loss: 1.019 acc: 10.27 time: 10.97\n",
            "[5,   200] loss: 0.993 acc: 9.38 time: 7.73\n",
            "[5,   300] loss: 0.954 acc: 9.67 time: 10.87\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 68.41 %\n",
            "Average loss on the 10000 test images: 0.906\n",
            "[6,   100] loss: 0.943 acc: 10.19 time: 9.50\n",
            "[6,   300] loss: 0.916 acc: 9.86 time: 8.07\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 69.97 %\n",
            "Average loss on the 10000 test images: 0.868\n",
            "[7,   100] loss: 0.886 acc: 10.55 time: 9.33\n",
            "[7,   200] loss: 0.871 acc: 9.84 time: 9.39\n",
            "[7,   300] loss: 0.869 acc: 10.59 time: 9.36\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 70.37 %\n",
            "Average loss on the 10000 test images: 0.841\n",
            "[8,   100] loss: 0.820 acc: 10.12 time: 10.89\n",
            "[8,   200] loss: 0.826 acc: 9.99 time: 7.69\n",
            "[8,   300] loss: 0.812 acc: 9.80 time: 11.07\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 71.84 %\n",
            "Average loss on the 10000 test images: 0.805\n",
            "[9,   100] loss: 0.785 acc: 9.72 time: 8.13\n",
            "[9,   200] loss: 0.778 acc: 10.43 time: 10.70\n",
            "[9,   300] loss: 0.758 acc: 10.16 time: 7.62\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 72.88 %\n",
            "Average loss on the 10000 test images: 0.803\n",
            "[10,   100] loss: 0.745 acc: 9.59 time: 10.17\n",
            "[10,   200] loss: 0.752 acc: 10.18 time: 10.74\n",
            "[10,   300] loss: 0.739 acc: 9.91 time: 10.73\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 73.79 %\n",
            "Average loss on the 10000 test images: 0.770\n",
            "[11,   100] loss: 0.663 acc: 10.52 time: 9.08\n",
            "[11,   200] loss: 0.644 acc: 10.48 time: 10.70\n",
            "[11,   300] loss: 0.649 acc: 10.17 time: 8.17\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 75.89 %\n",
            "Average loss on the 10000 test images: 0.701\n",
            "[12,   100] loss: 0.615 acc: 10.48 time: 9.40\n",
            "[12,   200] loss: 0.620 acc: 10.32 time: 9.24\n",
            "[12,   300] loss: 0.608 acc: 10.01 time: 9.50\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.17 %\n",
            "Average loss on the 10000 test images: 0.698\n",
            "[13,   100] loss: 0.619 acc: 10.20 time: 10.91\n",
            "[13,   200] loss: 0.608 acc: 9.62 time: 8.62\n",
            "[13,   300] loss: 0.609 acc: 9.91 time: 10.02\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.57 %\n",
            "Average loss on the 10000 test images: 0.697\n",
            "[14,   100] loss: 0.610 acc: 9.99 time: 8.06\n",
            "[14,   200] loss: 0.598 acc: 10.59 time: 10.69\n",
            "[14,   300] loss: 0.587 acc: 9.87 time: 10.50\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.26 %\n",
            "Average loss on the 10000 test images: 0.698\n",
            "[15,   100] loss: 0.580 acc: 10.16 time: 10.83\n",
            "[15,   200] loss: 0.594 acc: 9.97 time: 7.84\n",
            "[15,   300] loss: 0.586 acc: 10.38 time: 10.76\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.81 %\n",
            "Average loss on the 10000 test images: 0.687\n",
            "[16,   100] loss: 0.590 acc: 9.71 time: 9.62\n",
            "[16,   200] loss: 0.587 acc: 10.11 time: 9.63\n",
            "[16,   300] loss: 0.579 acc: 10.11 time: 8.87\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.70 %\n",
            "Average loss on the 10000 test images: 0.688\n",
            "[17,   100] loss: 0.575 acc: 10.13 time: 8.50\n",
            "[17,   200] loss: 0.566 acc: 9.65 time: 10.21\n",
            "[17,   300] loss: 0.570 acc: 9.90 time: 8.60\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.72 %\n",
            "Average loss on the 10000 test images: 0.682\n",
            "[18,   100] loss: 0.560 acc: 10.05 time: 10.93\n",
            "[18,   200] loss: 0.562 acc: 10.39 time: 7.68\n",
            "[18,   300] loss: 0.565 acc: 9.79 time: 10.56\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.23 %\n",
            "Average loss on the 10000 test images: 0.678\n",
            "[19,   100] loss: 0.564 acc: 9.80 time: 8.38\n",
            "[19,   200] loss: 0.560 acc: 9.79 time: 10.30\n",
            "[19,   300] loss: 0.562 acc: 10.25 time: 8.02\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.14 %\n",
            "Average loss on the 10000 test images: 0.678\n",
            "[20,   100] loss: 0.550 acc: 10.40 time: 9.20\n",
            "[20,   200] loss: 0.550 acc: 10.00 time: 9.80\n",
            "[20,   300] loss: 0.561 acc: 10.38 time: 9.36\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.10 %\n",
            "Average loss on the 10000 test images: 0.677\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgKuSZ8n7YI3"
      },
      "source": [
        "# Write report (37 points)\n",
        "\n",
        "本次作業主要有3個tasks需要大家完成，在A4.pdf中有希望大家達成的baseline **(不能低於baseline最多2%，沒有達到不會給全部分數)**，report的撰寫請大家根據以下要求完成，就請大家將嘗試的結果寫在report裡，祝大家順利！\n",
        "\n",
        "1. (13 points) Train a ResNet18 on the Rotation task and report the test performance. Discuss why such a task helps in learning features that are generalizable to other visual tasks.\n",
        "\n",
        "2. (12 points) Initializing from the Rotation model or from random weights, fine-tune only the weights of the final block of convolutional layers and linear layer on the supervised CIFAR10 classification task. Report the test results and compare the performance of these two models. Provide your observations and insights. You can also discuss how the performance of pre-trained models affects downstream tasks, the performance of fine-tuning different numbers of layers, and so on.\n",
        "\n",
        "3. (12 points) Initializing from the Rotation model or from random weights, train the full network on the supervised CIFAR10 classification task. Report the test results and compare the performance of these two models. Provide your observations and insights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FJMA6ZU7YI4"
      },
      "source": [
        "# Extra Credit (13 points)\n",
        "\n",
        "上面基本的code跟report最高可以拿到87分，這個加分部分並沒有要求同學們一定要做，若同學們想要獲得更高的分數可以根據以下的加分要求來獲得加分。\n",
        "\n",
        "- In Figure 5(b) from the Gidaris et al. paper, the authors show a plot of CIFAR10 classification performance vs. number of training examples per category for a supervised CIFAR10 model vs. a RotNet model with the final layers fine-tuned on CIFAR10. The plot shows that pre-training on the Rotation task can be advantageous when only a small amount of labeled data is available. Using your RotNet fine-tuning code and supervised CIFAR10 training code from the main assignment, try to create a similar plot by performing supervised fine-tuning/training on only a subset of CIFAR10.\n",
        "- Use a more advanced model than ResNet18 to try to get higher accuracy on the rotation prediction task, as well as for transfer to supervised CIFAR10 classification.\n",
        "  \n",
        "- If you have a good amount of compute at your disposal, try to train a rotation prediction model on the larger ImageNette dataset (still smaller than ImageNet, though).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWX6wJme7YI4"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "aaa478f9632825e83f6a2247407c7a2930de96a6810af7910643e423346524f9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}